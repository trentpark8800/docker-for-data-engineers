# Dockerized Spark Development Environment

A containerized Apache Spark development environment designed for data engineers and developers who want to quickly set up a complete Spark ecosystem with Jupyter notebooks, PostgreSQL integration, and S3 connectivity.

## Purpose

This project provides a ready-to-use Docker-based Spark development environment that eliminates the complexity of local Spark installations and dependency management. Perfect for:

- Learning Apache Spark and PySpark
- Data engineering experimentation
- Rapid prototyping of Spark applications
- Educational workshops and tutorials

**Note:** This was used as part of a YouTube tutorial I created which you can find (here)[].